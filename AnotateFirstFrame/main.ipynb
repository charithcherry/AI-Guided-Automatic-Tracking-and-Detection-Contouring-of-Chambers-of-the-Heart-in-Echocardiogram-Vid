{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a79588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AdjustBoundary import adjustContour\n",
    "from helper import find_files, read_image, selectFrames, save_images\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "image_files = find_files()\n",
    "frNum = int(input('Enter frame number: '))\n",
    "selectFrames(image_files, frNum-1, frNum)   # Show the selected frames of all the images\n",
    "i = 0\n",
    "crop = 30\n",
    "\n",
    "while i < len(image_files):\n",
    "    ctr = None\n",
    "    name = image_files[i].split(\".\")[0]\n",
    "    c_save = name + \"_inx.txt\"\n",
    "\n",
    "    if os.path.isfile(c_save):           ctr = np.loadtxt(c_save)\n",
    "    im = read_image(image_files[i], frNum)\n",
    "    im = im[crop:-crop,crop:-crop]\n",
    "\n",
    "    exit_mode = adjustContour(im, ctr, im.shape, crop, c_save)\n",
    "    save_images(image_files[i], frNum)\n",
    "    if exit_mode == 'exit':                 break\n",
    "    if exit_mode == 'previous':             i = i - 1\n",
    "    if exit_mode == 'next':                 i = i + 1\n",
    "    if exit_mode == 'done':                 pass\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import opencv \n",
    "import cv2 \n",
    "\n",
    "# Read image \n",
    "src = cv2.imread(\"save/IM_0013_1.jpg\", cv2.IMREAD_GRAYSCALE); \n",
    "\n",
    "# Basic threhold example \n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \n",
    "cv2.imwrite(\"opencv-threshold-example.jpg\", dst); \n",
    "\n",
    "# # Thresholding with maxValue set to 128\n",
    "# th, dst = cv2.threshold(src, 0, 128, cv2.THRESH_BINARY); \n",
    "# cv2.imwrite(\"opencv-thresh-binary-maxval.jpg\", dst); \n",
    "\n",
    "# # Thresholding with threshold value set 127 \n",
    "# th, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY); \n",
    "# cv2.imwrite(\"opencv-thresh-binary.jpg\", dst); \n",
    "\n",
    "# # Thresholding using THRESH_BINARY_INV \n",
    "# th, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY_INV); \n",
    "# cv2.imwrite(\"opencv-thresh-binary-inv.jpg\", dst); \n",
    "\n",
    "# # Thresholding using THRESH_TRUNC \n",
    "# th, dst = cv2.threshold(src,127,255, cv2.THRESH_TRUNC); \n",
    "# cv2.imwrite(\"opencv-thresh-trunc.jpg\", dst); \n",
    "\n",
    "# # Thresholding using THRESH_TOZERO \n",
    "# th, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO); \n",
    "# cv2.imwrite(\"opencv-thresh-tozero.jpg\", dst); \n",
    "\n",
    "# # Thresholding using THRESH_TOZERO_INV \n",
    "# th, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO_INV); \n",
    "# cv2.imwrite(\"opencv-thresh-to-zero-inv.jpg\", dst); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect the contours on the binary image using cv2.CHAIN_APPROX_NONE\n",
    "contours, hierarchy = cv2.findContours(image=dst, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "                                     \n",
    "# draw contours on the original image\n",
    "image_copy = dst.copy()\n",
    "cv2.drawContours(image=image_copy, contours=contours[9], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "               \n",
    "# see the results\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"opencv-threshold-example.jpg\")\n",
    "cv2.drawContours(image=src, contours=contours[9], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "cv2.imshow('None approximation', src)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', src)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6380dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_index(contours):\n",
    "    a=[x for x in range(0,len(contours))]\n",
    "\n",
    "    maxval=0\n",
    "    secmaxval=0\n",
    "    i=0\n",
    "    c=0\n",
    "    d=0\n",
    "    for i,x in zip(a,contours):\n",
    "        area = cv2.contourArea(x)\n",
    "        if area>maxval:\n",
    "            maxval=area\n",
    "            c=i\n",
    "    for i,x in zip(a,contours):\n",
    "        area=cv2.contourArea(x)\n",
    "        if area>secmaxval and area!=maxval:\n",
    "            secmaxval=area\n",
    "            d=i\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b33536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "src = cv2.imread(\"save/IM_0008_1.jpg\", cv2.IMREAD_GRAYSCALE); \n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \n",
    "cv2.imwrite(\"opencv-threshold-example.jpg\", dst);\n",
    "contours, hierarchy = cv2.findContours(image=dst, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "image_copy = cv2.imread(\"opencv-threshold-example.jpg\")\n",
    "cv2.drawContours(image=image_copy, contours=contours[cal_index(contours)], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30baab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "src = cv2.imread(\"save/IM_0008_1.jpg\", cv2.IMREAD_GRAYSCALE); \n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \n",
    "cv2.imwrite(\"opencv-threshold-example.jpg\", dst);\n",
    "contours, hierarchy = cv2.findContours(image=dst, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "image_copy = cv2.imread(\"opencv-threshold-example.jpg\")\n",
    "cv2.drawContours(image=image_copy, contours=contours[cal_index(contours)], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4647f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_manipulation(src):\n",
    "    (th, dst) = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \n",
    "    cv2.imwrite(\"opencv-threshold-example.jpg\", dst);\n",
    "    contours, hierarchy = cv2.findContours(image=dst, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "    image_copy = cv2.imread(\"opencv-threshold-example.jpg\")\n",
    "    cv2.drawContours(image=image_copy, contours=contours[cal_index(contours)], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "    return image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ddec0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10416/1024360780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_manipulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Original'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "cap=cv2.VideoCapture('mov-series-008.avi')\n",
    "while(1):\n",
    "    ret, frame = cap.read()  \n",
    "    frame=cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    frame=image_manipulation(frame)\n",
    "    cv2.imshow('Original', frame)  \n",
    "    key=cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "%matplotlib inline\n",
    "image = cv2.imread('opencv-threshold-example.jpg') # reads the image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) # convert to HSV\n",
    "figure_size = 9 # the dimension of the x and y axis of the kernal.\n",
    "new_image = cv2.blur(image,(figure_size, figure_size))\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.subplot(121), plt.imshow(cv2.cvtColor(image, cv2.COLOR_HSV2RGB)),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_HSV2RGB)),plt.title('Mean filter')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "879651ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "src = cv2.imread(\"save/IM_0008_1.jpg\"); \n",
    "src = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "src = cv2.blur(src,(2,2))\n",
    "src=cv2.cvtColor(src, cv2.COLOR_HSV2RGB)\n",
    "src=cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
    "th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY);\n",
    "\n",
    "cv2.imwrite(\"opencv-threshold-example.jpg\", dst);\n",
    "contours, hierarchy = cv2.findContours(image=dst, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "image_copy = cv2.imread(\"opencv-threshold-example.jpg\")\n",
    "cv2.drawContours(image=image_copy, contours=contours[156], contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b609c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv2.imread(\"save/IM_0008_1.jpg\")\n",
    "pts=np.array([[398,68],[645,491],[611,511],[571,525],[524,541],[489,549],[451,554],[414,556],[372,556],[335,553],[299,546],[258,536],[230,525],[199,512],[158,493],[271,287],[524,281]])\n",
    "rect = cv2.boundingRect(pts)\n",
    "x,y,w,h = rect\n",
    "croped = img[y:y+h, x:x+w].copy()\n",
    "\n",
    "## (2) make mask\n",
    "pts = pts - pts.min(axis=0)\n",
    "\n",
    "mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "## (3) do bit-op\n",
    "dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "\n",
    "## (4) add the white background\n",
    "bg = np.ones_like(croped, np.uint8)*255\n",
    "cv2.bitwise_not(bg,bg, mask=mask)\n",
    "dst2 = bg+ dst\n",
    "\n",
    "\n",
    "cv2.imwrite(\"croped.png\", croped)\n",
    "cv2.imwrite(\"mask.png\", mask)\n",
    "cv2.imwrite(\"dst.png\", dst)\n",
    "cv2.imwrite(\"dst2.png\", dst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"save/IM_0013_1.jpg\")\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "\n",
    "mask = np.zeros((height, width), dtype=np.uint8)\n",
    "points=np.array([[398,68],[645,491],[611,511],[571,525],[524,541],[489,549],[451,554],[414,556],[372,556],[335,553],[299,546],[258,536],[230,525],[199,512],[158,493],[271,287],[524,281]])\n",
    "cv2.fillPoly(mask, points, (255))\n",
    "\n",
    "res = cv2.bitwise_and(img,img,mask = mask)\n",
    "\n",
    "rect = cv2.boundingRect(points) # returns (x,y,w,h) of the rect\n",
    "cropped = res[rect[1]: rect[1] + rect[3], rect[0]: rect[0] + rect[2]]\n",
    "\n",
    "cv2.imshow(\"cropped\" , cropped )\n",
    "cv2.imshow(\"same size\" , res)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83475693",
   "metadata": {},
   "outputs": [],
   "source": [
    "points=np.array([[398,68],[645,491],[611,511],[571,525],[524,541],[489,549],[451,554],[414,556],[372,556],[335,553],[299,546],[258,536],[230,525],[199,512],[158,493],[271,287],[524,281]])\n",
    "hull = cv.convexHull(points[, hull[, clockwise[, returnPoints]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e37c0051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "#The MIT License (MIT)\n",
    "#Copyright (c) 2016 Massimiliano Patacchiola\n",
    "#\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF \n",
    "#MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY \n",
    "#CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE \n",
    "#SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "#In this example the Particle Filter is used in order to stabilise some noisy detection.\n",
    "#The Backprojection algorithm is used in order to find the pixels that have the same HSV \n",
    "#histogram of a predefined template. The template is a subframe of the main image or an external\n",
    "#matrix that can be used as a filter. We track the object taking the contour with the largest area\n",
    "#returned by a binary mask (blue rectangle). The center of the contour is the tracked point. \n",
    "#To test the Particle Filter we inject noise in the measurements returned by the Backprojection. \n",
    "#The Filter can absorbe the noisy measurements, giving a stable estimation of the target center (green dot).\n",
    "\n",
    "#COLOR CODE:\n",
    "#BLUE: the rectangle containing the target. Noise makes it shaky (unstable measurement).\n",
    "#GREEN: the point estimated from the Particle Filter.\n",
    "#RED: the particles generated by the filter.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepgaze.color_detection import BackProjectionColorDetector\n",
    "from deepgaze.mask_analysis import BinaryMaskAnalyser\n",
    "from deepgaze.motion_tracking import ParticleFilter\n",
    "\n",
    "#Set to true if you want to use the webcam instead of the video.\n",
    "#In this case you have to provide a valid tamplate, it can be\n",
    "#a solid color you want to track or a frame containint your face.\n",
    "#Substitute the frame to the default template.png.\n",
    "USE_WEBCAM = False\n",
    "\n",
    "template = cv2.imread('save/IM_0004_1.jpg') #Load the image\n",
    "if(USE_WEBCAM == False):\n",
    "    video_capture = cv2.VideoCapture(\"./mov-series-004.avi\")\n",
    "else:\n",
    "    video_capture = cv2.VideoCapture(0) #Open the webcam\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(\"./cows_output.avi\", fourcc, 25.0, (1920,1080))\n",
    "\n",
    "#Declaring the binary mask analyser object\n",
    "my_mask_analyser = BinaryMaskAnalyser()\n",
    "\n",
    "#Defining the deepgaze color detector object\n",
    "my_back_detector = BackProjectionColorDetector()\n",
    "my_back_detector.setTemplate(template) #Set the template \n",
    "\n",
    "#Filter parameters\n",
    "tot_particles = 2500\n",
    "#Standard deviation which represent how to spread the particles\n",
    "#in the prediction phase.\n",
    "std = 15\n",
    "my_particle = ParticleFilter(1920, 1080, tot_particles)\n",
    "#Probability to get a faulty measurement\n",
    "noise_probability = 0.15 #in range [0, 1.0]\n",
    "\n",
    "while(True):\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if(frame is None): break #check for empty frames\n",
    "\n",
    "    #Return the binary mask from the backprojection algorithm\n",
    "    frame_mask = my_back_detector.returnMask(frame, morph_opening=True, blur=True, kernel_size=5, iterations=2)\n",
    "\n",
    "    if(my_mask_analyser.returnNumberOfContours(frame_mask) > 0):\n",
    "        #Use the binary mask to find the contour with largest area\n",
    "        #and the center of this contour which is the point we\n",
    "        #want to track with the particle filter\n",
    "        x_rect,y_rect,w_rect,h_rect = my_mask_analyser.returnMaxAreaRectangle(frame_mask)\n",
    "        x_center, y_center = my_mask_analyser.returnMaxAreaCenter(frame_mask)\n",
    "        #Adding noise to the coords\n",
    "        coin = np.random.uniform()\n",
    "        if(coin >= 1.0-noise_probability): \n",
    "            x_noise = int(np.random.uniform(-300, 300))\n",
    "            y_noise = int(np.random.uniform(-300, 300))\n",
    "        else: \n",
    "            x_noise = 0\n",
    "            y_noise = 0\n",
    "        x_rect += x_noise\n",
    "        y_rect += y_noise\n",
    "        x_center += x_noise\n",
    "        y_center += y_noise\n",
    "        cv2.rectangle(frame, (x_rect,y_rect), (x_rect+w_rect,y_rect+h_rect), [255,0,0], 2) #BLUE rect\n",
    "\n",
    "    #Predict the position of the target\n",
    "    my_particle.predict(x_velocity=0, y_velocity=0, std=std)\n",
    "\n",
    "    #Drawing the particles.\n",
    "    my_particle.drawParticles(frame)\n",
    "\n",
    "    #Estimate the next position using the internal model\n",
    "    x_estimated, y_estimated, _, _ = my_particle.estimate()\n",
    "    cv2.circle(frame, (x_estimated, y_estimated), 3, [0,255,0], 5) #GREEN dot\n",
    "\n",
    "    #Update the filter with the last measurements\n",
    "    my_particle.update(x_center, y_center)\n",
    "\n",
    "    #Resample the particles\n",
    "    my_particle.resample()\n",
    "\n",
    "    #Writing in the output file\n",
    "    out.write(frame)\n",
    "\n",
    "\n",
    "    #Showing the frame and waiting\n",
    "    #for the exit command\n",
    "    cv2.imshow('Original', frame) #show on window\n",
    "    #cv2.imshow('Mask', frame_mask) #show on window\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Release the camera\n",
    "\n",
    "print(\"Bye...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f059a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def edge_detect(file_name, tresh_min, tresh_max):\n",
    "    image = cv2.imread(file_name)\n",
    "    im_bw = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    (thresh, im_bw) = cv2.threshold(im_bw, tresh_min, tresh_max, 0)\n",
    "    cv2.imwrite('bw_'+file_name, im_bw)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(im_bw, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "    cv2.imwrite('cnt_'+file_name, image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    edge_detect('IM_0004_1.jpg', 128, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639b609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12eb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
