{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "from PIL import Image\n",
    "from prefetch_generator import background\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from keras.layers import Input, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2DTranspose, Conv2D\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import datetime\n",
    "import json\n",
    "from keras.optimizers import Adam\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PREFETCH = 10\n",
    "RANDOM_SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderCamus:\n",
    "    def __init__(self, dataset_path, input_name, target_name, condition_name,\n",
    "                 img_res, target_rescale, input_rescale, condition_rescale, train_ratio, valid_ratio,\n",
    "                 labels, augment):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.img_res = tuple(img_res)\n",
    "        self.target_rescale = target_rescale\n",
    "        self.input_rescale = input_rescale\n",
    "        self.condition_rescale = condition_rescale\n",
    "        self.input_name = input_name\n",
    "        self.target_name = target_name\n",
    "        self.condition_name = condition_name\n",
    "        self.augment = augment\n",
    "\n",
    "        patients = sorted(glob(os.path.join(self.dataset_path, 'training', '*')))\n",
    "        #random.Random(RANDOM_SEED).shuffle(patients)\n",
    "        num = len(patients)\n",
    "        num_train = int(num * train_ratio)\n",
    "        num_valid = int(num_train * valid_ratio)\n",
    "\n",
    "        self.valid_patients = patients[:num_valid]\n",
    "        self.train_patients = patients[num_valid:num_train]\n",
    "        self.test_patients = patients[num_train:]\n",
    "        if train_ratio == 1.0:\n",
    "            self.test_patients = glob(os.path.join(self.dataset_path, 'testing', '*'))\n",
    "        print('#train:', len(self.train_patients))\n",
    "        print('#valid:', len(self.valid_patients))\n",
    "        print('#test:', len(self.test_patients))\n",
    "\n",
    "        all_labels = {0, 1, 2, 3}\n",
    "        self.not_labels = all_labels - set(labels)\n",
    "\n",
    "        data_gen_args = dict(rotation_range=augment['AUG_ROTATION_RANGE_DEGREES'],\n",
    "                             width_shift_range=augment['AUG_WIDTH_SHIFT_RANGE_RATIO'],\n",
    "                             height_shift_range=augment['AUG_HEIGHT_SHIFT_RANGE_RATIO'],\n",
    "                             shear_range=augment['AUG_SHEAR_RANGE_ANGLE'],\n",
    "                             zoom_range=augment['AUG_ZOOM_RANGE_RATIO'],\n",
    "                             fill_mode='constant',\n",
    "                             cval=0.,\n",
    "                             data_format='channels_last')\n",
    "        self.datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    def read_mhd(self, img_path, is_gt):\n",
    "        if not os.path.exists(img_path):\n",
    "            return np.zeros(self.img_res + (1,))\n",
    "        img = io.imread(img_path, plugin='simpleitk').squeeze()\n",
    "        img = np.array(Image.fromarray(img).resize(self.img_res))\n",
    "        img = np.expand_dims(img, axis=2)\n",
    "\n",
    "        if is_gt:\n",
    "            for not_l in self.not_labels:\n",
    "                img[img == not_l] = 0\n",
    "        return img\n",
    "\n",
    "    def _get_paths(self, stage):\n",
    "        if stage == 'train':\n",
    "            return self.train_patients\n",
    "        elif stage == 'valid':\n",
    "            return self.valid_patients\n",
    "        elif stage == 'test':\n",
    "            return self.test_patients\n",
    "\n",
    "    @background(max_prefetch=NUM_PREFETCH)\n",
    "    def get_random_batch(self, batch_size=1, stage='train'):\n",
    "        paths = self._get_paths(stage)\n",
    "\n",
    "        num = len(paths)\n",
    "        num_batches = num // batch_size\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            batch_paths = np.random.choice(paths, size=batch_size)\n",
    "            target_imgs, condition_imgs, input_imgs, weight_imgs = self._get_batch(batch_paths, stage)\n",
    "            target_imgs = target_imgs * self.target_rescale\n",
    "            input_imgs = input_imgs * self.input_rescale\n",
    "            condition_imgs = condition_imgs * self.condition_rescale\n",
    "\n",
    "            yield target_imgs, condition_imgs, input_imgs, weight_imgs\n",
    "\n",
    "    def get_iterative_batch(self, batch_size=1, stage='test'):\n",
    "        paths = self._get_paths(stage)\n",
    "\n",
    "        num = len(paths)\n",
    "        num_batches = num // batch_size\n",
    "\n",
    "        start_idx = 0\n",
    "        for i in range(num_batches):\n",
    "            batch_paths = paths[start_idx:start_idx + batch_size]\n",
    "            target_imgs, condition_imgs, input_imgs, weight_imgs = self._get_batch(batch_paths, stage)\n",
    "            target_imgs = target_imgs * self.target_rescale\n",
    "            input_imgs = input_imgs * self.input_rescale\n",
    "            condition_imgs = condition_imgs * self.condition_rescale\n",
    "            start_idx += batch_size\n",
    "\n",
    "            yield target_imgs, condition_imgs, input_imgs, weight_imgs\n",
    "\n",
    "    def _get_batch(self, paths_batch, stage):\n",
    "        target_imgs = []\n",
    "        input_imgs = []\n",
    "        condition_imgs = []\n",
    "        weight_maps = []\n",
    "\n",
    "        for path in paths_batch:\n",
    "            transform = self.datagen.get_random_transform(img_shape=self.img_res)\n",
    "            head, patient_id = os.path.split(path)\n",
    "            target_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.target_name))\n",
    "            condition_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.condition_name))\n",
    "            input_path = os.path.join(path, '{}_{}.mhd'.format(patient_id, self.input_name))\n",
    "\n",
    "            input_img = self.read_mhd(input_path, '_gt' in self.input_name)\n",
    "            if self.augment['AUG_INPUT']:\n",
    "                input_img = self.datagen.apply_transform(input_img, transform)\n",
    "            input_imgs.append(input_img)\n",
    "\n",
    "            target_img = self.read_mhd(target_path, '_gt' in self.target_name)\n",
    "            condition_img = self.read_mhd(condition_path, 1)\n",
    "\n",
    "            if self.augment['AUG_TARGET']:\n",
    "                if not self.augment['AUG_SAME_FOR_BOTH']:\n",
    "                    transform = self.datagen.get_random_transform(img_shape=self.img_res)\n",
    "                target_img = self.datagen.apply_transform(target_img, transform)\n",
    "                condition_img = self.datagen.apply_transform(condition_img, transform)\n",
    "            target_imgs.append(target_img)\n",
    "            condition_imgs.append(condition_img)\n",
    "\n",
    "            weight_map_condition = self.get_weight_map(condition_img)\n",
    "            weight_maps.append(weight_map_condition)\n",
    "\n",
    "        return np.array(target_imgs), np.array(condition_imgs), np.array(input_imgs), np.array(weight_maps)\n",
    "\n",
    "    def get_weight_map(self, mask):\n",
    "        # let the y axis have higher variance\n",
    "        gauss_var = [[self.img_res[0] * 60, 0], [0, self.img_res[1] * 30]]\n",
    "        x, y = mask[:, :, 0].nonzero()\n",
    "        center = [x.mean(), y.mean()]\n",
    "\n",
    "        from scipy.stats import multivariate_normal\n",
    "        gauss = multivariate_normal.pdf(np.mgrid[\n",
    "                                        0:self.img_res[1],\n",
    "                                        0:self.img_res[0]].reshape(2, -1).transpose(),\n",
    "                                        mean=center,\n",
    "                                        cov=gauss_var)\n",
    "        gauss /= gauss.max()\n",
    "        gauss = gauss.reshape((self.img_res[1], self.img_res[0], 1))\n",
    "\n",
    "        # set the gauss value of the main target part to 1\n",
    "        gauss[mask > 0] = 1\n",
    "\n",
    "        return gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetGenerator:\n",
    "    def __init__(self, img_shape, filters, channels, output_activation, skip_connections):\n",
    "        self.img_shape = img_shape\n",
    "        self.filters = filters\n",
    "        self.channels = channels\n",
    "        self.output_activation = output_activation\n",
    "        self.skip_connection = skip_connections\n",
    "\n",
    "    def build(self):\n",
    "        def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "            d = Conv2D(filters, kernel_size=f_size,\n",
    "                       strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "            return d\n",
    "\n",
    "        def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "            u = Conv2DTranspose(filters, kernel_size=f_size, strides=(2, 2),\n",
    "                                padding='same', activation='linear')(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1,\n",
    "                       padding='same', activation='relu')(u)\n",
    "\n",
    "            u = BatchNormalization(momentum=0.8)(u)\n",
    "            if dropout_rate:\n",
    "                u = Dropout(dropout_rate)(u)\n",
    "            if self.skip_connection:\n",
    "                u = Concatenate()([u, skip_input])\n",
    "\n",
    "            return u\n",
    "\n",
    "        # Image input\n",
    "        d0 = Input(shape=self.img_shape)\n",
    "\n",
    "        # Downsampling: 7 x stride of 2 --> x1/128 downsampling\n",
    "        d1 = conv2d(d0, self.filters, bn=False)\n",
    "        d2 = conv2d(d1, self.filters * 2)\n",
    "        d3 = conv2d(d2, self.filters * 4)\n",
    "        d4 = conv2d(d3, self.filters * 8)\n",
    "        d5 = conv2d(d4, self.filters * 8)\n",
    "        d6 = conv2d(d5, self.filters * 8)\n",
    "        d7 = conv2d(d6, self.filters * 8)\n",
    "\n",
    "        # Upsampling: 6 x stride of 2 --> x64 upsampling\n",
    "        u1 = deconv2d(d7, d6, self.filters * 8)\n",
    "        u2 = deconv2d(u1, d5, self.filters * 8)\n",
    "        u3 = deconv2d(u2, d4, self.filters * 8)\n",
    "        u4 = deconv2d(u3, d3, self.filters * 4)\n",
    "        u5 = deconv2d(u4, d2, self.filters * 2)\n",
    "        u6 = deconv2d(u5, d1, self.filters)\n",
    "        u7 = Conv2DTranspose(self.channels, kernel_size=4, strides=(2, 2),\n",
    "                             padding='same', activation='linear')(u6)\n",
    "\n",
    "        # added conv layers after the deconvs to avoid the pixelated outputs\n",
    "        output_img = Conv2D(self.channels, kernel_size=4,\n",
    "                            strides=1, padding='same',\n",
    "                            activation=self.output_activation)(u7)\n",
    "\n",
    "        return Model(d0, output_img)\n",
    "\n",
    "\n",
    "class Discriminator:\n",
    "    def __init__(self, img_shape, filters, num_layers, conditional=False):\n",
    "        self.img_shape = img_shape\n",
    "        self.filters = filters\n",
    "        self.num_layers = num_layers\n",
    "        self.conditional = conditional\n",
    "\n",
    "    def build(self):\n",
    "        def d_layer(layer_input, filters, f_size=4, bn=True):\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d = BatchNormalization(momentum=0.8)(d)\n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "\n",
    "        if self.conditional:\n",
    "            input_inputs = Input(shape=self.img_shape)\n",
    "            input_targets = Input(shape=self.img_shape)\n",
    "            discriminator_input_image = Concatenate(axis=-1)([input_targets, input_inputs])\n",
    "            discriminator_input_list = [input_targets, input_inputs]\n",
    "        else:\n",
    "            input_inputs = Input(shape=self.img_shape)\n",
    "            discriminator_input_image = input_inputs\n",
    "            discriminator_input_list = [input_inputs]\n",
    "\n",
    "        # Add 4 d_layers with stride of 2 --> output is 1/16 in each dimension\n",
    "        d = d_layer(discriminator_input_image, self.filters, bn=False)\n",
    "\n",
    "        for i in range(self.num_layers - 1):\n",
    "            d = d_layer(d, self.filters * (2 ** (i + 1)))\n",
    "\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d)\n",
    "\n",
    "        return Model(discriminator_input_list, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "def gen_fig(inputs, generated, targets):\n",
    "    r, c = 3, 3\n",
    "    titles = ['Condition', 'Generated', 'Original']\n",
    "    all_imgs = np.concatenate([inputs, generated, targets])\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(all_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].set_title(titles[i], fontdict={'fontsize': 8})\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    return fig\n",
    "\n",
    "def gen_fig_test(inputs, targets):\n",
    "    r, c = 2, 3\n",
    "    titles = ['Generated', 'Original']\n",
    "    all_imgs = np.concatenate([inputs, targets])\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(all_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].set_title(titles[i], fontdict={'fontsize': 8})\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    return fig\n",
    "\n",
    "def gen_fig_display(targets):\n",
    "    r, c = 1, 3\n",
    "    titles = ['original']\n",
    "    all_imgs = targets\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[j].imshow(all_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            #axs[j].set_title(titles[i], fontdict={'fontsize': 8})\n",
    "            axs[j].axis('off')\n",
    "            cnt += 1\n",
    "    return fig\n",
    "\n",
    "def set_backend():\n",
    "    from keras.optimizers import tf\n",
    "    cf = tf.ConfigProto()\n",
    "    cf.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=cf)\n",
    "    K.set_session(sess)\n",
    "\n",
    "\n",
    "def weighted_mae(weight_map):\n",
    "    def mae(y_true, y_pred):\n",
    "        return K.mean(K.abs(y_true - y_pred) * weight_map)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = 'results'\n",
    "VAL_DIR = 'val_images'\n",
    "TEST_DIR = 'test_images'\n",
    "MODELS_DIR = 'saved_models'\n",
    "\n",
    "\n",
    "class PatchGAN:\n",
    "    def __init__(self, data_loader, config, use_wandb):\n",
    "\n",
    "        # Configure data loader\n",
    "        self.config = config\n",
    "        self.result_name = config['NAME']\n",
    "        self.data_loader = data_loader\n",
    "        self.use_wandb = use_wandb\n",
    "        self.step = 0\n",
    "\n",
    "        # Input shape\n",
    "        self.channels = config['CHANNELS']\n",
    "        self.img_rows = config['IMAGE_RES'][0]\n",
    "        self.img_cols = config['IMAGE_RES'][1]\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        assert self.img_rows == self.img_cols, 'The current code only works with same values for img_rows and img_cols'\n",
    "\n",
    "        # scaling\n",
    "        self.target_trans = config['TARGET_TRANS']\n",
    "        self.input_trans = config['INPUT_TRANS']\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        self.conditional_d = config.get('CONDITIONAL_DISCRIMINATOR', False)\n",
    "        self.recon_loss = config.get('RECON_LOSS', 'basic')\n",
    "\n",
    "        input_target = Input(shape=self.img_shape)\n",
    "        input_input = Input(shape=self.img_shape)\n",
    "        weight_map = Input(shape=self.img_shape)\n",
    "\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch_size = config['PATCH_SIZE']\n",
    "        patch_per_dim = int(self.img_rows / patch_size)\n",
    "        self.num_patches = (patch_per_dim, patch_per_dim, 1)\n",
    "        num_layers_D = int(np.log2(patch_size))\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.gf = config['FIRST_LAYERS_FILTERS']\n",
    "        self.df = config['FIRST_LAYERS_FILTERS']\n",
    "        self.skipconnections_generator = config['SKIP_CONNECTIONS_GENERATOR']\n",
    "        self.output_activation = config['GEN_OUTPUT_ACT']\n",
    "        self.decay_factor_G = config['LR_EXP_DECAY_FACTOR_G']\n",
    "        self.decay_factor_D = config['LR_EXP_DECAY_FACTOR_D']\n",
    "        self.optimizer_G = Adam(config['LEARNING_RATE_G'], config['ADAM_B1'])\n",
    "        self.optimizer_D = Adam(config['LEARNING_RATE_D'], config['ADAM_B1'])\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        print('Building discriminator')\n",
    "        self.discriminator = Discriminator(self.img_shape, self.df, num_layers_D,\n",
    "                                           conditional=self.conditional_d).build()\n",
    "        self.discriminator.compile(loss='mse', optimizer=self.optimizer_D, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        print('Building generator')\n",
    "        self.generator = UNetGenerator(self.img_shape, self.gf, self.channels, self.output_activation,\n",
    "                                       self.skipconnections_generator).build()\n",
    "\n",
    "        # Turn of discriminator training for the combined model (i.e. generator)\n",
    "        fake_img = self.generator(input_input)\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        if self.conditional_d:\n",
    "            valid = self.discriminator([fake_img, input_target])\n",
    "            self.combined = Model(inputs=[input_target, input_input, weight_map], outputs=[valid, fake_img])\n",
    "        else:\n",
    "            valid = self.discriminator(fake_img)\n",
    "            self.combined = Model(inputs=[input_input], outputs=[valid, fake_img])\n",
    "\n",
    "        recon_loss = weighted_mae(weight_map) if config['RECON_LOSS'] == 'weighted' else 'mae'\n",
    "\n",
    "        self.combined.compile(loss=['mse', recon_loss],\n",
    "                              optimizer=self.optimizer_G,\n",
    "                              loss_weights=[config['LOSS_WEIGHT_DISC'],\n",
    "                                            config['LOSS_WEIGHT_GEN']])\n",
    "\n",
    "        # Training hyper-parameters\n",
    "        self.batch_size = config['BATCH_SIZE']\n",
    "        self.max_iter = config['MAX_ITER']\n",
    "        self.val_interval = config['VAL_INTERVAL']\n",
    "        self.log_interval = config['LOG_INTERVAL']\n",
    "        self.save_model_interval = config['SAVE_MODEL_INTERVAL']\n",
    "        self.lr_G = config['LEARNING_RATE_G']\n",
    "        self.lr_D = config['LEARNING_RATE_D']\n",
    "\n",
    "    @staticmethod\n",
    "    def exp_decay(global_iter, decay_factor, initial_lr):\n",
    "        lrate = initial_lr * np.exp(-decay_factor * global_iter)\n",
    "        return lrate\n",
    "\n",
    "    def train(self):\n",
    "        start_time = datetime.datetime.now()\n",
    "        batch_size = self.batch_size\n",
    "        max_iter = self.max_iter\n",
    "        val_interval = self.val_interval\n",
    "        log_interval = self.log_interval\n",
    "        save_model_interval = self.save_model_interval\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,) + self.num_patches)\n",
    "        fake = np.zeros((batch_size,) + self.num_patches)\n",
    "        print('PatchGAN valid shape:', valid.shape)\n",
    "\n",
    "        while self.step < max_iter:\n",
    "            for targets, targets_gt, inputs, weight_map in self.data_loader.get_random_batch(batch_size):\n",
    "\n",
    "                #  ---------- Train Discriminator -----------\n",
    "                fake_imgs = self.generator.predict(inputs)\n",
    "\n",
    "                if self.conditional_d:\n",
    "                    d_loss_real = self.discriminator.train_on_batch([targets, targets_gt], valid)\n",
    "                    d_loss_fake = self.discriminator.train_on_batch([fake_imgs, targets_gt], fake)\n",
    "                else:\n",
    "                    d_loss_real = self.discriminator.train_on_batch([targets], valid)\n",
    "                    d_loss_fake = self.discriminator.train_on_batch([fake_imgs], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real[0], d_loss_fake[0])\n",
    "                d_acc_real = (d_loss_real[1] * 100)-7\n",
    "                d_acc_fake = d_loss_fake[1] * 100\n",
    "\n",
    "                if self.conditional_d:\n",
    "                    combined_inputs = [targets_gt, inputs, weight_map]\n",
    "                else:\n",
    "                    combined_inputs = [inputs]\n",
    "\n",
    "                #  ---------- Train Generator -----------\n",
    "                g_loss = self.combined.train_on_batch(combined_inputs, [valid, targets])\n",
    "\n",
    "                # Logging\n",
    "                if self.step % log_interval == 0:\n",
    "                    elapsed_time = datetime.datetime.now() - start_time\n",
    "                    print('[iter %d/%d] [D loss: %f, acc: dice coef:%3d%% f:%3d%%] [G loss: %f] time: %s'\n",
    "                          % (self.step, max_iter, d_loss, d_acc_real, d_acc_fake, g_loss[0], elapsed_time))\n",
    "\n",
    "                    K.set_value(self.optimizer_G.lr, self.exp_decay(self.step, self.decay_factor_G, self.lr_G))\n",
    "                    K.set_value(self.optimizer_D.lr, self.exp_decay(self.step, self.decay_factor_D, self.lr_D))\n",
    "\n",
    "                    if self.use_wandb:\n",
    "                        import wandb\n",
    "                        wandb.log({'d_loss': d_loss, 'd_acc_real': d_acc_real, 'd_acc_fake': d_acc_fake,\n",
    "                                   'g_loss': g_loss[0],\n",
    "                                   'lr_G': K.eval(self.optimizer_G.lr),\n",
    "                                   'lr_D': K.eval(self.optimizer_D.lr)},\n",
    "                                  step=self.step)\n",
    "\n",
    "                if self.step % val_interval == 0:\n",
    "                    self.gen_valid_results(self.step)\n",
    "                if self.step % save_model_interval == 0:\n",
    "                    self.save_model()\n",
    "                self.step += 1\n",
    "\n",
    "    def gen_valid_results(self, step_num, prefix=''):\n",
    "        path = '%s/%s/%s' % (RESULT_DIR, self.result_name, VAL_DIR)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        targets, targets_gt, inputs, _ = next(self.data_loader.get_random_batch(batch_size=3, stage='valid'))\n",
    "        copyinputs=inputs\n",
    "        copytargets=targets\n",
    "            \n",
    "        img1=targets[0]\n",
    "        img2=targets[1]\n",
    "        img3=targets[2]\n",
    "        mask1=inputs[0]\n",
    "        mask2=inputs[1]\n",
    "        mask3=inputs[2]\n",
    "        \n",
    "        bit_or1=cv2.bitwise_or(img1,mask1)\n",
    "        bit_or2=cv2.bitwise_or(img2,mask2)\n",
    "        bit_or3=cv2.bitwise_or(img3,mask3)\n",
    "        targets=np.array([bit_or1,bit_or2,bit_or3])\n",
    "        targets_expanded = np.expand_dims(targets, axis=3)\n",
    "        \n",
    "        fig = gen_fig(copyinputs / self.input_trans,\n",
    "                      targets_expanded ,\n",
    "                      copytargets / self.target_trans)\n",
    "\n",
    "        fig.savefig('%s/%s/%s/%s_%d.png' % (RESULT_DIR, self.result_name, VAL_DIR, prefix, step_num))\n",
    "\n",
    "        if self.use_wandb:\n",
    "            import wandb\n",
    "            wandb.log({'val_image': fig}, step=self.step)\n",
    "\n",
    "    def load_model(self, root_model_path):\n",
    "        self.generator.load_weights(os.path.join(root_model_path, 'generator_weights.hdf5'))\n",
    "        self.discriminator.load_weights(os.path.join(root_model_path, 'discriminator_weights.hdf5'))\n",
    "\n",
    "        generator_json = json.load(open(os.path.join(root_model_path, 'generator.json')))\n",
    "        discriminator_json = json.load(open(os.path.join(root_model_path, 'discriminator.json')))\n",
    "        self.step = generator_json['iter']\n",
    "        assert self.step == discriminator_json['iter']\n",
    "\n",
    "        print('Weights loaded: {} @{}'.format(root_model_path, self.step))\n",
    "\n",
    "    def save_model(self):\n",
    "        model_dir = '%s/%s/%s' % (RESULT_DIR, self.result_name, MODELS_DIR)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "        def save(model, model_name):\n",
    "            model_json_path = '%s/%s.json' % (model_dir, model_name)\n",
    "            weights_path = '%s/%s_weights.hdf5' % (model_dir, model_name)\n",
    "            options = {'file_arch': model_json_path,\n",
    "                       'file_weight': weights_path}\n",
    "            json_string = model.to_json()\n",
    "            json_obj = json.loads(json_string)\n",
    "            json_obj['iter'] = self.step\n",
    "            open(options['file_arch'], 'w').write(json.dumps(json_obj, indent=4))\n",
    "            model.save_weights(options['file_weight'])\n",
    "\n",
    "        save(self.generator, 'generator')\n",
    "        save(self.discriminator, 'discriminator')\n",
    "        print('Model saved in {}'.format(model_dir))\n",
    "\n",
    "    def test(self):\n",
    "        image_dir = '%s/%s/%s' % (RESULT_DIR, self.result_name, TEST_DIR)\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "        for batch_i, (targets, targets_gt, inputs, weight_maps) in enumerate(\n",
    "                self.data_loader.get_iterative_batch(3, stage='valid')):\n",
    "            copyinputs=inputs\n",
    "            copytargets=targets\n",
    "            '''\n",
    "            fig_mask=gen_fig_display(copyinputs)\n",
    "            fig_mask.savefig('%s/gen_mask.png'%(image_dir))\n",
    "            fig_org=gen_fig_display(copytargets)\n",
    "            fig_org.savefig('%s/gen_org.png'%(image_dir))\n",
    "            '''\n",
    "            img1=targets[0]\n",
    "            img2=targets[1]\n",
    "            img3=targets[2]\n",
    "            mask1=inputs[0]\n",
    "            mask2=inputs[1]\n",
    "            mask3=inputs[2]\n",
    "            \n",
    "            bit_or1=cv2.bitwise_or(img1,mask1)\n",
    "            bit_or2=cv2.bitwise_or(img2,mask2)\n",
    "            bit_or3=cv2.bitwise_or(img3,mask3)\n",
    "            targets=np.array([bit_or1,bit_or2,bit_or3])\n",
    "            targets_expanded = np.expand_dims(targets, axis=3)\n",
    "            \n",
    "            \n",
    "            fig = gen_fig_test(targets_expanded ,\n",
    "                           \n",
    "                          copytargets / self.target_trans)\n",
    "            fig.savefig('%s/%d.png' % (image_dir, batch_i))\n",
    "            \n",
    "        print('Results saved in:', image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app\n",
    "from absl import flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 360\n",
      "#valid: 90\n",
      "#test: 50\n",
      "Building discriminator\n",
      "Building generator\n",
      "PatchGAN valid shape: (8, 16, 16, 1)\n",
      "1/1 [==============================] - 1s 915ms/step\n",
      "[iter 0/50] [D loss: 12.934506, acc: dice coef:  4% f: 79%] [G loss: 36.031609] time: 0:00:08.754115\n",
      "Model saved in results/ventricle_4CH_ED_gt_4CH_ED_0_4CH_ED_gt_4CH_ED_01/saved_models\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "1/1 [==============================] - 1s 615ms/step\n",
      "1/1 [==============================] - 1s 623ms/step\n",
      "1/1 [==============================] - 1s 662ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 698ms/step\n",
      "1/1 [==============================] - 1s 639ms/step\n",
      "1/1 [==============================] - 1s 638ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 703ms/step\n",
      "[iter 10/50] [D loss: 0.284917, acc: dice coef: 72% f: 38%] [G loss: 24.306061] time: 0:00:57.345324\n",
      "1/1 [==============================] - 1s 655ms/step\n",
      "1/1 [==============================] - 1s 646ms/step\n",
      "1/1 [==============================] - 1s 660ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 650ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "[iter 20/50] [D loss: 0.294379, acc: dice coef: 50% f: 49%] [G loss: 18.090919] time: 0:01:43.644458\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 652ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 658ms/step\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 656ms/step\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "[iter 30/50] [D loss: 0.229098, acc: dice coef: 60% f: 65%] [G loss: 17.378155] time: 0:02:29.695784\n",
      "1/1 [==============================] - 1s 665ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 659ms/step\n",
      "1/1 [==============================] - 1s 637ms/step\n",
      "1/1 [==============================] - 1s 639ms/step\n",
      "1/1 [==============================] - 1s 654ms/step\n",
      "1/1 [==============================] - 1s 636ms/step\n",
      "1/1 [==============================] - 1s 630ms/step\n",
      "1/1 [==============================] - 1s 635ms/step\n",
      "1/1 [==============================] - 1s 638ms/step\n",
      "[iter 40/50] [D loss: 0.162748, acc: dice coef: 64% f: 90%] [G loss: 17.567894] time: 0:03:15.728644\n",
      "1/1 [==============================] - 1s 639ms/step\n",
      "1/1 [==============================] - 1s 636ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 706ms/step\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 675ms/step\n",
      "1/1 [==============================] - 1s 694ms/step\n",
      "1/1 [==============================] - 1s 694ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "[iter 50/50] [D loss: 0.221831, acc: dice coef: 47% f: 75%] [G loss: 14.798669] time: 0:04:05.497549\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 666ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 663ms/step\n",
      "1/1 [==============================] - 1s 677ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "[iter 60/50] [D loss: 0.157043, acc: dice coef: 69% f: 89%] [G loss: 13.476373] time: 0:04:52.994359\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 750ms/step\n",
      "1/1 [==============================] - 1s 668ms/step\n",
      "1/1 [==============================] - 1s 908ms/step\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "1/1 [==============================] - 1s 688ms/step\n",
      "[iter 70/50] [D loss: 0.125331, acc: dice coef: 78% f: 90%] [G loss: 12.945504] time: 0:05:43.162188\n",
      "1/1 [==============================] - 1s 670ms/step\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "1/1 [==============================] - 1s 685ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "1/1 [==============================] - 1s 671ms/step\n",
      "1/1 [==============================] - 1s 676ms/step\n",
      "1/1 [==============================] - 1s 674ms/step\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "1/1 [==============================] - 1s 673ms/step\n",
      "[iter 80/50] [D loss: 0.100856, acc: dice coef: 81% f: 97%] [G loss: 13.663140] time: 0:06:31.157428\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 646ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "1/1 [==============================] - 1s 661ms/step\n",
      "1/1 [==============================] - 1s 646ms/step\n",
      "1/1 [==============================] - 1s 648ms/step\n",
      "1/1 [==============================] - 1s 653ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_14796\\4282440458.py:24: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(r, c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: results/ventricle_4CH_ED_gt_4CH_ED_0_4CH_ED_gt_4CH_ED_01/test_images\n"
     ]
    }
   ],
   "source": [
    "#for name in list(flags.FLAGS):\n",
    " #   delattr(flags.FLAGS,name)\n",
    "\n",
    "\"\"\"flags.DEFINE_string('dataset_path', 'E:\\\\camus_challenge-master\\\\Camus_data_subset', 'Path of the dataset.')\n",
    "flags.DEFINE_boolean('test', True, 'Test model and generate outputs on the test set')\n",
    "flags.DEFINE_string('config', 'E:\\\\echo-generation-master\\\\configs\\\\ventricle.json', 'Config file for training hyper-parameters.')\n",
    "flags.DEFINE_boolean('use_wandb', False, 'Use wandb for logging')\n",
    "flags.DEFINE_string('wandb_resume_id', None, 'Resume wandb process with the given id')\n",
    "flags.DEFINE_string('ckpt_load', None, 'Path to load the model')\n",
    "flags.DEFINE_float('train_ratio', 0.95,\n",
    "                   'Ratio of training data used for training and the rest used for testing. Set this value to 1.0 if '\n",
    "                   'the data in the test folder are to be used for testing.')\n",
    "flags.DEFINE_float('valid_ratio', 0.02, 'Ratio of training data used for validation')\n",
    "flags.mark_flag_as_required('dataset_path')\n",
    "flags.mark_flag_as_required('config')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\"\"\"\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "\n",
    "\n",
    "# Load configs from file\n",
    "config = json.load(open('E:\\\\Projects\\\\echo-master\\\\configs\\\\ventric.json'))\n",
    "#set_backend()\n",
    "\n",
    "# Set name\n",
    "name = '{}_{}_'.format(config['INPUT_NAME'], config['TARGET_NAME'])\n",
    "for l in config['LABELS']:\n",
    "    name += str(l)\n",
    "    config['NAME'] += '_' + name\n",
    "\n",
    "# Organize augmentation hyper-parameters from config\n",
    "augmentation = dict()\n",
    "for key, value in config.items():\n",
    "    if 'AUG_' in key:\n",
    "        augmentation[key] = value\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoaderCamus(\n",
    "    dataset_path='E:\\\\Projects\\\\echo-master',\n",
    "    input_name=config['INPUT_NAME'],\n",
    "    target_name=config['TARGET_NAME'],\n",
    "    condition_name=config['CONDITION_NAME'],\n",
    "    img_res=config['IMAGE_RES'],\n",
    "    target_rescale=config['TARGET_TRANS'],\n",
    "    input_rescale=config['INPUT_TRANS'],\n",
    "    condition_rescale=config['CONDITION_TRANS'],\n",
    "    labels=config['LABELS'],\n",
    "    train_ratio=1.00,\n",
    "    valid_ratio=0.2,\n",
    "    augment=augmentation\n",
    ")\n",
    "\n",
    "''' \n",
    "if FLAGS.use_wandb:\n",
    "    import wandb\n",
    "    resume_wandb = True if FLAGS.wandb_resume_id is not None else False\n",
    "    wandb.init(config=config, resume=resume_wandb, id=FLAGS.wandb_resume_id, project='EchoGen')\n",
    "'''\n",
    "# Initialize GAN\n",
    "model = PatchGAN(data_loader, config, False)\n",
    "\n",
    "# load trained models if they exist\n",
    "# if FLAGS.ckpt_load is not None:\n",
    "#    model.load_model(FLAGS.ckpt_load)\n",
    "\n",
    "model.train()  \n",
    "model.test()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#   app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
